import json
from pathlib import Path

# --- ì„¤ì • ---
# í—¤ë” íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ë¶„í•  ì²˜ë¦¬ëœ íŒŒì¼ë“¤)
INPUT_DIRECTORY = Path("./processed_headers")

# ìƒì„±ëœ JSON ë ˆì´ë¸”ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
LABEL_DIRECTORY = Path("./output_labels")

# ìµœì¢… Alpaca ë°ì´í„°ì…‹ì„ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (JSONLë¡œ ë³€ê²½)
OUTPUT_FILE = Path("./header.jsonl")

# LoRA í•™ìŠµì— ì‚¬ìš©í•  ì¼ê´€ëœ ì§€ì‹œë¬¸ (ì˜ë¬¸ìœ¼ë¡œ ìˆ˜ì •ë¨)
# ì´ ì§€ì‹œë¬¸ì€ ë°ì´í„°ì…‹ì˜ ëª¨ë“  ìƒ˜í”Œì— ë™ì¼í•˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.
INSTRUCTION = "Extract all public API identifiers from the Objective-C header file that must be excluded from obfuscation."


# ---

def read_file_with_encoding(file_path: Path) -> str:
    """
    ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ì‹œë„í•´ì„œ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.
    """
    for encoding in ['utf-8', 'latin-1', 'cp1252', 'mac-roman']:
        try:
            return file_path.read_text(encoding=encoding)
        except UnicodeDecodeError:
            continue
    raise UnicodeDecodeError(f"ëª¨ë“  ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path.name}")


def build_alpaca_dataset():
    """
    processed_headers ë””ë ‰í† ë¦¬ì˜ í—¤ë” íŒŒì¼ë“¤ê³¼ í•´ë‹¹í•˜ëŠ” output_labelsì˜ JSON íŒŒì¼ë“¤ì„ ì¡°í•©í•˜ì—¬
    LoRA í•™ìŠµì„ ìœ„í•œ Alpaca í˜•ì‹ì˜ ìµœì¢… ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not INPUT_DIRECTORY.is_dir():
        print(f"ì˜¤ë¥˜: '{INPUT_DIRECTORY}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € split_large_headers.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    if not LABEL_DIRECTORY.is_dir():
        print(f"ì˜¤ë¥˜: '{LABEL_DIRECTORY}' ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € generate_labels.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    print("Alpaca ë°ì´í„°ì…‹ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    dataset_entries = 0

    # í—¤ë” íŒŒì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìˆœíšŒ (processed_headersì— ëª¨ë“  íŒŒì¼ì´ ìˆìŒ)
    header_files = list(INPUT_DIRECTORY.glob("*.h"))
    total_files = len(header_files)

    if total_files == 0:
        print("ì²˜ë¦¬í•  í—¤ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. split_large_headers.pyë¥¼ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ì´ {total_files}ê°œì˜ í—¤ë” íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

    # ìµœì¢… ë°ì´í„°ì…‹ì„ JSONL íŒŒì¼ë¡œ ì €ì¥
    try:
        with OUTPUT_FILE.open("w", encoding="utf-8") as f:
            for i, header_path in enumerate(header_files):
                # í•´ë‹¹í•˜ëŠ” ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œ
                label_name = header_path.with_suffix(".json").name
                label_path = LABEL_DIRECTORY / label_name

                if not label_path.exists():
                    print(f"  - [{i + 1}/{total_files}] âš ï¸ ê²½ê³ : ë ˆì´ë¸” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆë›°ê¸°: {label_name}")
                    continue

                try:
                    # ë‹¤ì¤‘ ì¸ì½”ë”© ì§€ì›ìœ¼ë¡œ íŒŒì¼ ì½ê¸°
                    header_content = read_file_with_encoding(header_path)
                    label_content_string = label_path.read_text(encoding="utf-8")

                    if not header_content.strip() or not label_content_string.strip():
                        print(f"  - [{i + 1}/{total_files}] â„¹ï¸ ì •ë³´: í—¤ë” ë˜ëŠ” ë ˆì´ë¸” íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœë‹ˆë‹¤: {header_path.name}")
                        continue

                    # JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦
                    json.loads(label_content_string)

                    data_entry = {
                        "instruction": INSTRUCTION,
                        "input": header_content,
                        "output": label_content_string
                    }

                    # ê° data_entryë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì¤„ë°”ê¿ˆ ë¬¸ìì™€ í•¨ê»˜ íŒŒì¼ì— ì“´ë‹¤.
                    f.write(json.dumps(data_entry, ensure_ascii=False) + "\n")
                    dataset_entries += 1
                    print(f"  - [{i + 1}/{total_files}] âœ… ì²˜ë¦¬ ì™„ë£Œ: {header_path.name}")

                except UnicodeDecodeError as e:
                    print(f"  - [{i + 1}/{total_files}] âŒ ì¸ì½”ë”© ì˜¤ë¥˜: {header_path.name} - {e}")
                except json.JSONDecodeError:
                    print(f"  - [{i + 1}/{total_files}] âŒ ì˜¤ë¥˜: JSON ë ˆì´ë¸” íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆë›°ê¸°: {label_path.name}")
                except Exception as e:
                    print(f"  - [{i + 1}/{total_files}] âŒ ì˜¤ë¥˜: íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ ({header_path.name}): {e}")

        print(f"\nâœ… ì‘ì—… ì™„ë£Œ! ì´ {dataset_entries}ê°œì˜ ìƒ˜í”Œì„ '{OUTPUT_FILE}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print(f"ì„±ê³µë¥ : {dataset_entries}/{total_files} ({dataset_entries / total_files * 100:.1f}%)")

        if dataset_entries < total_files:
            missing_labels = total_files - dataset_entries
            print(f"\nğŸ“ ì°¸ê³ : {missing_labels}ê°œì˜ í—¤ë” íŒŒì¼ì— ëŒ€í•œ ë ˆì´ë¸”ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("ëˆ„ë½ëœ íŒŒì¼ë“¤ì— ëŒ€í•´ generate_labels.pyë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë³´ì„¸ìš”.")

        # ë¶„í• ëœ íŒŒì¼ë“¤ì— ëŒ€í•œ ì •ë³´ ì œê³µ
        part_files = [f for f in header_files if "_part" in f.name]
        if part_files:
            print(f"\nğŸ“„ ë¶„í• ëœ íŒŒì¼: {len(part_files)}ê°œ (ì „ì²´ {len(header_files)}ê°œ ì¤‘)")
            original_files = len(header_files) - len(part_files)
            print(f"ğŸ“„ ì›ë³¸ íŒŒì¼: {original_files}ê°œ")

    except Exception as e:
        print(f"\nâŒ ìµœì¢… íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    build_alpaca_dataset()