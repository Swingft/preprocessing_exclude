import json
from pathlib import Path
from tqdm import tqdm
import subprocess
import tempfile
import re
import concurrent.futures

import prompts
from gemini_handler.gemini_handler import GeminiHandler

# --- í…ŒìŠ¤íŠ¸ ì „ìš© ì„¤ì • (Test-only Configuration) ---
ANALYZER_EXECUTABLE = "./SwiftASTAnalyzer/.build/release/SwiftASTAnalyzer"
OUTPUT_DIR = Path("./output")

# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
TEST_BASE_DIR = OUTPUT_DIR / "generated_code" / "test"
TEST_INPUTS_BASE_DIR = OUTPUT_DIR / "inputs" / "test"
TEST_LABELS_BASE_DIR = OUTPUT_DIR / "outputs" / "test"


# ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ íŒŒì¼ë“¤ì€ ë™ì ìœ¼ë¡œ ìƒì„±ë¨


# --- í—¬í¼ í•¨ìˆ˜ (Helper Functions) ---

def run_swift_analyzer_on_code(swift_code: str) -> str | None:
    """Swift ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ AST ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not swift_code or not swift_code.strip():
        return None
    try:
        with tempfile.NamedTemporaryFile(mode='w+', suffix='.swift', delete=False, encoding='utf-8') as temp_file:
            temp_file.write(swift_code)
            temp_file_path = temp_file.name

        command = [ANALYZER_EXECUTABLE, temp_file_path]
        process = subprocess.run(command, capture_output=True, text=True, encoding='utf-8', timeout=60)
        Path(temp_file_path).unlink()

        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
        if process.returncode != 0:
            print(f"  âš ï¸ Swift analyzer exited with code {process.returncode}")
            if process.stderr:
                print(f"  âš ï¸ Stderr: {process.stderr[:200]}...")
            return None

        # ì¶œë ¥ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not process.stdout or not process.stdout.strip():
            print(f"  âš ï¸ Swift analyzer returned empty output")
            return None

        # ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        output = process.stdout.strip()

        # JSONì´ ì‹œì‘ë˜ëŠ” ë¶€ë¶„ ì°¾ê¸° (ì²« ë²ˆì§¸ '{' ë¬¸ì)
        json_start = output.find('{')
        if json_start == -1:
            print(f"  âš ï¸ No JSON found in Swift analyzer output")
            return None

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_part = output[json_start:]

        # JSON ìœ íš¨ì„± ê²€ì‚¬
        try:
            json.loads(json_part)
            return json_part
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ Swift analyzer returned invalid JSON: {e}")
            print(f"  âš ï¸ JSON part: {json_part[:200]}...")
            return None

    except subprocess.TimeoutExpired:
        print(f"  âš ï¸ Swift analyzer timed out")
        if 'temp_file_path' in locals() and Path(temp_file_path).exists():
            Path(temp_file_path).unlink()
        return None
    except Exception as e:
        print(f"  âš ï¸ Swift analyzer failed: {e}")
        if 'temp_file_path' in locals() and Path(temp_file_path).exists():
            Path(temp_file_path).unlink()
        return None


def extract_json_block(text: str) -> str | None:
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not text or not text.strip():
        return None

    # JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ ì‹œë„
    match = re.search(r"```json\s*(\{[\s\S]*?\})\s*```", text, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        try:
            json.loads(json_str)  # ìœ íš¨ì„± ê²€ì‚¬
            return json_str
        except json.JSONDecodeError:
            pass

    # ì§ì ‘ JSON í˜•íƒœì¸ì§€ í™•ì¸
    if text.strip().startswith("{"):
        try:
            json.loads(text.strip())  # ìœ íš¨ì„± ê²€ì‚¬
            return text.strip()
        except json.JSONDecodeError:
            pass

    return None


def get_test_projects() -> list:
    """test ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  í”„ë¡œì íŠ¸ í´ë”ë¥¼ ì§€ì •ëœ ìˆœì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ì²˜ë¦¬ ìˆœì„œ ê°•ì œ: UIKit+SPM_2 -> ConfettiSwiftUI -> iOS -> UIKit+SPM_1
    priority_order = [
        "Code_UIKit+SPM_2_combined",
        "Code_ConfettiSwiftUI",
        "Code_iOS",
        "Code_UIKit+SPM_1_combined"
    ]

    test_projects = []
    if TEST_BASE_DIR.exists():
        existing_projects = set()
        for item in TEST_BASE_DIR.iterdir():
            if item.is_dir():
                existing_projects.add(item.name)

        # ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ ì¶”ê°€
        for project in priority_order:
            if project in existing_projects:
                test_projects.append(project)
                existing_projects.remove(project)

        # ë‚˜ë¨¸ì§€ í”„ë¡œì íŠ¸ë“¤ì€ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì¶”ê°€
        for project in sorted(existing_projects):
            test_projects.append(project)

    return test_projects


def get_test_project_paths(project_name: str) -> dict:
    """í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "code": TEST_BASE_DIR / project_name,
        "inputs": TEST_INPUTS_BASE_DIR / project_name,
        "labels": TEST_LABELS_BASE_DIR / project_name
    }


def is_valid_json_file(file_path: Path) -> bool:
    """JSON íŒŒì¼ì´ ìœ íš¨í•œì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    try:
        if not file_path.exists() or file_path.stat().st_size <= 10:  # ìµœì†Œ í¬ê¸° ì²´í¬
            return False
        content = file_path.read_text(encoding='utf-8').strip()
        if not content or content == "":
            return False
        json.loads(content)  # JSON ìœ íš¨ì„± ê²€ì‚¬
        return True
    except (json.JSONDecodeError, UnicodeDecodeError, OSError):
        return False


# --- API í˜¸ì¶œ í•¨ìˆ˜ ---

def safe_gemini_label_request(prompt: str) -> str | None:
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("    - Calling Gemini for label generation...")
    try:
        prompt_config = {"messages": [{"role": "user", "parts": [prompt]}]}
        response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")

        if not response or not response.strip():
            return None

        json_str = extract_json_block(response)
        if not json_str:
            print(f"    âš ï¸ Failed to extract valid JSON from response")
            return None

        # í•œ ë²ˆ ë” ìœ íš¨ì„± ê²€ì‚¬
        try:
            json.loads(json_str)
            return json_str
        except json.JSONDecodeError:
            print(f"    âš ï¸ Extracted JSON is invalid")
            return None

    except Exception as e:
        print(f"    âŒ Label generation request failed: {e}")
        return None


# --- ë©”ì¸ ì²˜ë¦¬ ë¡œì§ ---

def discover_test_files():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ì—ì„œ Swift íŒŒì¼ë“¤ì„ ë°œê²¬í•©ë‹ˆë‹¤."""
    test_tasks = []
    test_projects = get_test_projects()

    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë“¤ ê²€ìƒ‰ ì¤‘...")

    for project in test_projects:
        project_code_dir = TEST_BASE_DIR / project
        if not project_code_dir.exists():
            print(f"  - {project}: ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            continue

        swift_files = list(project_code_dir.glob("*.swift"))
        print(f"  - {project}: {len(swift_files)}ê°œì˜ Swift íŒŒì¼ ë°œê²¬")

        for swift_file in swift_files:
            task_name = swift_file.stem
            test_tasks.append({
                "project": project,
                "filename": task_name,
                "file_path": swift_file
            })

    return test_tasks


def process_test_sample(test_task: dict):
    """í•˜ë‚˜ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ ë¼ë²¨ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    project = test_task["project"]
    filename = test_task["filename"]
    file_path = test_task["file_path"]

    paths = get_test_project_paths(project)
    code_path = paths["code"] / f"{filename}.swift"
    input_path = paths["inputs"] / f"{filename}.txt"
    label_path = paths["labels"] / f"{filename}.json"

    # ì´ë¯¸ ìœ íš¨í•œ ë¼ë²¨ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if is_valid_json_file(label_path):
        print(f"  - [TEST/{project}] `{filename}` - ì´ë¯¸ ì²˜ë¦¬ë¨, ìŠ¤í‚µ")
        return

    print(f"  - [TEST/{project}] `{filename}` ì²˜ë¦¬ ì¤‘...")

    # Swift ì½”ë“œ ì½ê¸°
    try:
        swift_code = code_path.read_text(encoding='utf-8')
        if not swift_code or not swift_code.strip():
            print(f"    âŒ Swift ì½”ë“œê°€ ë¹„ì–´ìˆìŒ")
            return
    except Exception as e:
        print(f"    âŒ Swift ì½”ë“œ ì½ê¸° ì‹¤íŒ¨: {e}")
        return

    # AST ë¶„ì„
    symbol_info_json = run_swift_analyzer_on_code(swift_code)
    if not symbol_info_json:
        print(f"    âŒ Swift analyzer ì‹¤íŒ¨ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•Šì€ JSON ë°˜í™˜")
        return

    # ë¼ë²¨ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì €ì¥
    try:
        label_prompt = prompts.GENERATE_LABEL_PROMPT.format(
            swift_code=swift_code,
            symbol_info_json=symbol_info_json
        )
        input_path.write_text(label_prompt, encoding='utf-8')
    except Exception as e:
        print(f"    âŒ ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return

    # ë¼ë²¨ ìƒì„± (Gemini 2.5 Pro ì‚¬ìš©)
    final_output_json_str = safe_gemini_label_request(label_prompt)
    if not final_output_json_str:
        print(f"    âŒ ìœ íš¨í•œ ë¼ë²¨ ìƒì„± ì‹¤íŒ¨")
        try:
            label_path.write_text('{"error": "generation_failed"}', encoding='utf-8')
        except Exception:
            pass
        return

    # ìµœì¢… ì €ì¥
    try:
        label_path.write_text(final_output_json_str, encoding='utf-8')
        print(f"    âœ… `{filename}` ì²˜ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"    âŒ ë¼ë²¨ ì €ì¥ ì‹¤íŒ¨: {e}")
        return


def assemble_test_datasets():
    """í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë³„ë¡œ ìµœì¢… ë°ì´í„°ì…‹ì„ ì¡°ë¦½í•©ë‹ˆë‹¤."""
    print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¡°ë¦½ ì¤‘...")

    test_projects = get_test_projects()
    all_test_data = []
    project_counts = {}

    for project in test_projects:
        print(f"\n  - {project} í”„ë¡œì íŠ¸ ì²˜ë¦¬ ì¤‘...")

        paths = get_test_project_paths(project)
        label_files = sorted(list(paths["labels"].glob("*.json")))

        if not label_files:
            print(f"    ë¼ë²¨ íŒŒì¼ ì—†ìŒ")
            project_counts[project] = 0
            continue

        project_data = []
        success_count = 0
        error_count = 0

        for label_path in tqdm(label_files, desc=f"{project} ë°ì´í„°ì…‹ ì¡°ë¦½"):
            try:
                # ìœ íš¨í•œ JSON íŒŒì¼ì¸ì§€ í™•ì¸
                if not is_valid_json_file(label_path):
                    error_count += 1
                    continue

                code_path = paths["code"] / (label_path.stem + ".swift")
                input_path = paths["inputs"] / (label_path.stem + ".txt")

                if not code_path.exists() or not input_path.exists():
                    error_count += 1
                    continue

                swift_code = code_path.read_text(encoding='utf-8')
                if not swift_code or not swift_code.strip():
                    error_count += 1
                    continue

                output_json_str = label_path.read_text(encoding='utf-8')
                input_prompt = input_path.read_text(encoding='utf-8')

                # input í”„ë¡¬í”„íŠ¸ì—ì„œ symbol_infoë¥¼ ì¶”ì¶œ
                symbol_info_json = None
                if "symbol_info_json=" in input_prompt:
                    match = re.search(r'symbol_info_json=(.+?)(?=\n\n|\Z)', input_prompt, re.DOTALL)
                    if match:
                        symbol_info_json = match.group(1).strip()

                # ë§Œì•½ ì¶”ì¶œì— ì‹¤íŒ¨í•˜ë©´ Swift analyzer ë‹¤ì‹œ ì‹¤í–‰
                if not symbol_info_json:
                    symbol_info_json = run_swift_analyzer_on_code(swift_code)
                    if not symbol_info_json:
                        error_count += 1
                        continue

                # JSON íŒŒì‹± ê²€ì¦
                try:
                    symbol_info_dict = json.loads(symbol_info_json)
                    output_dict = json.loads(output_json_str)
                except json.JSONDecodeError:
                    error_count += 1
                    continue

                # ìµœì¢… ë°ì´í„°ì…‹ ì—”íŠ¸ë¦¬ ìƒì„±
                entry = {
                    "instruction": "Identify which identifiers in the Swift code should be excluded from obfuscation based on the provided AST analysis, and provide detailed reasoning.",
                    "input": {
                        "swift_code": swift_code,
                        "symbol_info": symbol_info_dict
                    },
                    "output": output_dict
                }

                project_data.append(entry)
                all_test_data.append(entry)
                success_count += 1

            except Exception as e:
                error_count += 1
                print(f"\nâš ï¸ íŒŒì¼ ì¡°ë¦½ ì¤‘ ì—ëŸ¬ ë°œìƒ '{label_path.name}': {e}")

        project_counts[project] = success_count
        print(f"    {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")

        # í”„ë¡œì íŠ¸ë³„ ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
        if project_data:
            try:
                project_dataset_file = OUTPUT_DIR / f"test_{project}_dataset.jsonl"
                with open(project_dataset_file, "w", encoding="utf-8") as f:
                    for entry in project_data:
                        f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                print(f"    ì €ì¥ë¨: {project_dataset_file}")
            except Exception as e:
                print(f"    âŒ í”„ë¡œì íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")

    # ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥
    if all_test_data:
        try:
            all_test_dataset_file = OUTPUT_DIR / "all_test_dataset.jsonl"
            with open(all_test_dataset_file, "w", encoding="utf-8") as f:
                for entry in all_test_data:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            print(f"\nì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ë¨: {all_test_dataset_file}")
        except Exception as e:
            print(f"\nâŒ ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")

    return project_counts, len(all_test_data)


def main_test_pipeline():
    """í…ŒìŠ¤íŠ¸ ì „ìš© ë©”ì¸ íŒŒì´í”„ë¼ì¸"""
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ìš© Swift ì½”ë“œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")

    # í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    test_projects = get_test_projects()
    if not test_projects:
        print("âŒ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   {TEST_BASE_DIR} ë””ë ‰í† ë¦¬ì— í”„ë¡œì íŠ¸ í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    print(f"ë°œê²¬ëœ í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸: {test_projects}")

    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    for project in test_projects:
        paths = get_test_project_paths(project)
        for path in paths.values():
            path.mkdir(parents=True, exist_ok=True)

    # 1. í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ ë°œê²¬
    test_tasks = discover_test_files()
    if not test_tasks:
        print("âŒ ì²˜ë¦¬í•  Swift íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return

    print(f"\nì´ {len(test_tasks)}ê°œì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë°œê²¬")

    # 2. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒ˜í”Œ ìƒì„±
    print("\nğŸ”„ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ ì²˜ë¦¬ ì‹œì‘...")
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        list(tqdm(
            executor.map(process_test_sample, test_tasks),
            total=len(test_tasks),
            desc="í…ŒìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬ ì¤‘"
        ))

    # 3. ìµœì¢… ë°ì´í„°ì…‹ ì¡°ë¦½
    project_counts, total_count = assemble_test_datasets()

    # 4. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ¨ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    for project, count in project_counts.items():
        print(f"   - {project}: {count}ê°œ ë°ì´í„°")
    print(f"   - ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {total_count}ê°œ ìƒì„± ì™„ë£Œ")

    # ì €ì¥ëœ íŒŒì¼ë“¤ ì •ë¦¬
    print(f"\nğŸ“„ ìƒì„±ëœ ë°ì´í„°ì…‹ íŒŒì¼ë“¤:")
    for project in test_projects:
        if project_counts.get(project, 0) > 0:
            print(f"   - test_{project}_dataset.jsonl")
    if total_count > 0:
        print(f"   - all_test_dataset.jsonl")


if __name__ == "__main__":
    main_test_pipeline()