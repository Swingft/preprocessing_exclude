import json
from pathlib import Path
from tqdm import tqdm
import random
import time
import subprocess
import tempfile
import re
import itertools
import concurrent.futures

import prompts
from gemini_handler.gemini_handler import GeminiHandler
from claude_handler import ClaudeHandler

# --- ì„¤ì • (Configuration) ---
ANALYZER_EXECUTABLE = "./SwiftASTAnalyzer/.build/release/SwiftASTAnalyzer"
RULES_FILE = "./obfuscation_rules.json"
SAFE_PATTERNS_FILE = "./obfuscation_safe_patterns.json"
OUTPUT_DIR = Path("./output")

# ìƒì„±ê¸°ë³„ ë””ë ‰í† ë¦¬ ê²½ë¡œ
GEMINI_CODE_DIR = OUTPUT_DIR / "generated_code" / "gemini_generated"
CLAUDE_CODE_DIR = OUTPUT_DIR / "generated_code" / "claude_generated"
OLD_GEMINI_CODE_DIR = OUTPUT_DIR / "generated_code" / "old_gemini_generated"
OLD_CLAUDE_CODE_DIR = OUTPUT_DIR / "generated_code" / "old_claude_generated"

GEMINI_INPUTS_DIR = OUTPUT_DIR / "inputs" / "gemini_generated"
CLAUDE_INPUTS_DIR = OUTPUT_DIR / "inputs" / "claude_generated"
OLD_GEMINI_INPUTS_DIR = OUTPUT_DIR / "inputs" / "old_gemini_generated"
OLD_CLAUDE_INPUTS_DIR = OUTPUT_DIR / "inputs" / "old_claude_generated"

GEMINI_LABELS_DIR = OUTPUT_DIR / "outputs" / "gemini_generated"
CLAUDE_LABELS_DIR = OUTPUT_DIR / "outputs" / "claude_generated"
OLD_GEMINI_LABELS_DIR = OUTPUT_DIR / "outputs" / "old_gemini_generated"
OLD_CLAUDE_LABELS_DIR = OUTPUT_DIR / "outputs" / "old_claude_generated"

# ìµœì¢… ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ
FINAL_DATASET_GEMINI_ONLY = OUTPUT_DIR / "gemini_only_dataset.jsonl"
FINAL_DATASET_CLAUDE_ONLY = OUTPUT_DIR / "claude_only_dataset.jsonl"
FINAL_DATASET_COMBINED = OUTPUT_DIR / "exclude.jsonl"


# --- í—¬í¼ í•¨ìˆ˜ (Helper Functions) ---

def run_swift_analyzer_on_code(swift_code: str) -> str | None:
    if not swift_code or not swift_code.strip():
        return None
    try:
        with tempfile.NamedTemporaryFile(mode='w+', suffix='.swift', delete=False, encoding='utf-8') as temp_file:
            temp_file.write(swift_code)
            temp_file_path = temp_file.name

        command = [ANALYZER_EXECUTABLE, temp_file_path]
        process = subprocess.run(command, capture_output=True, text=True, encoding='utf-8', timeout=60)
        Path(temp_file_path).unlink()

        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ê²°ê³¼ í™•ì¸
        if process.returncode != 0:
            print(f"  âš ï¸ Swift analyzer exited with code {process.returncode}")
            if process.stderr:
                print(f"  âš ï¸ Stderr: {process.stderr[:200]}...")
            return None

        # ì¶œë ¥ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if not process.stdout or not process.stdout.strip():
            print(f"  âš ï¸ Swift analyzer returned empty output")
            return None

        # ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        output = process.stdout.strip()

        # JSONì´ ì‹œì‘ë˜ëŠ” ë¶€ë¶„ ì°¾ê¸° (ì²« ë²ˆì§¸ '{' ë¬¸ì)
        json_start = output.find('{')
        if json_start == -1:
            print(f"  âš ï¸ No JSON found in Swift analyzer output")
            return None

        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_part = output[json_start:]

        # JSON ìœ íš¨ì„± ê²€ì‚¬
        try:
            json.loads(json_part)
            return json_part
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ Swift analyzer returned invalid JSON: {e}")
            print(f"  âš ï¸ JSON part: {json_part[:200]}...")
            return None

    except subprocess.TimeoutExpired:
        print(f"  âš ï¸ Swift analyzer timed out")
        if 'temp_file_path' in locals() and Path(temp_file_path).exists():
            Path(temp_file_path).unlink()
        return None
    except Exception as e:
        print(f"  âš ï¸ Swift analyzer failed: {e}")
        if 'temp_file_path' in locals() and Path(temp_file_path).exists():
            Path(temp_file_path).unlink()
        return None


def extract_json_block(text: str) -> str | None:
    if not text or not text.strip():
        return None

    # JSON ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ ì‹œë„
    match = re.search(r"```json\s*(\{[\s\S]*?\})\s*```", text, re.DOTALL)
    if match:
        json_str = match.group(1).strip()
        try:
            json.loads(json_str)  # ìœ íš¨ì„± ê²€ì‚¬
            return json_str
        except json.JSONDecodeError:
            pass

    # ì§ì ‘ JSON í˜•íƒœì¸ì§€ í™•ì¸
    if text.strip().startswith("{"):
        try:
            json.loads(text.strip())  # ìœ íš¨ì„± ê²€ì‚¬
            return text.strip()
        except json.JSONDecodeError:
            pass

    return None


def get_generator_paths(generator_type: str) -> dict:
    """ìƒì„±ê¸° íƒ€ì…ì— ë”°ë¼ ì˜¬ë°”ë¥¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if generator_type == "gemini":
        return {
            "code": GEMINI_CODE_DIR,
            "inputs": GEMINI_INPUTS_DIR,
            "labels": GEMINI_LABELS_DIR
        }
    elif generator_type == "claude":
        return {
            "code": CLAUDE_CODE_DIR,
            "inputs": CLAUDE_INPUTS_DIR,
            "labels": CLAUDE_LABELS_DIR
        }
    elif generator_type == "old_gemini":
        return {
            "code": OLD_GEMINI_CODE_DIR,
            "inputs": OLD_GEMINI_INPUTS_DIR,
            "labels": OLD_GEMINI_LABELS_DIR
        }
    elif generator_type == "old_claude":
        return {
            "code": OLD_CLAUDE_CODE_DIR,
            "inputs": OLD_CLAUDE_INPUTS_DIR,
            "labels": OLD_CLAUDE_LABELS_DIR
        }
    else:
        raise ValueError(f"Unknown generator type: {generator_type}")


def is_valid_json_file(file_path: Path) -> bool:
    """JSON íŒŒì¼ì´ ìœ íš¨í•œì§€ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    try:
        if not file_path.exists() or file_path.stat().st_size <= 10:  # ìµœì†Œ í¬ê¸° ì²´í¬
            return False
        content = file_path.read_text(encoding='utf-8').strip()
        if not content or content == "":
            return False
        json.loads(content)  # JSON ìœ íš¨ì„± ê²€ì‚¬
        return True
    except (json.JSONDecodeError, UnicodeDecodeError, OSError):
        return False


# --- API í˜¸ì¶œ ë˜í¼ í•¨ìˆ˜ ---

def safe_gemini_code_request(prompt: str) -> str | None:
    print("    - Calling Gemini for code generation...")
    try:
        prompt_config = {"messages": [{"role": "user", "parts": [prompt]}]}
        response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")

        if not response or not response.strip():
            return None

        # Swift ì½”ë“œ ë¸”ë¡ ì œê±°
        code = re.sub(r"^\s*```swift\s*", "", response, flags=re.MULTILINE)
        code = re.sub(r"\s*```\s*$", "", code, flags=re.MULTILINE)

        final_code = code.strip()
        return final_code if final_code else None

    except Exception as e:
        print(f"    âŒ Code generation request failed: {e}")
        return None


def safe_gemini_label_request(prompt: str) -> str | None:
    print("    - Calling Gemini for label generation...")
    try:
        prompt_config = {"messages": [{"role": "user", "parts": [prompt]}]}
        response = GeminiHandler.ask(prompt_config, model_name="gemini-2.5-pro")

        if not response or not response.strip():
            return None

        json_str = extract_json_block(response)
        if not json_str:
            print(f"    âš ï¸ Failed to extract valid JSON from response")
            return None

        # í•œ ë²ˆ ë” ìœ íš¨ì„± ê²€ì‚¬
        try:
            json.loads(json_str)
            return json_str
        except json.JSONDecodeError:
            print(f"    âš ï¸ Extracted JSON is invalid")
            return None

    except Exception as e:
        print(f"    âŒ Label generation request failed: {e}")
        return None


def safe_claude_code_request(prompt: str) -> str | None:
    print("    - Calling Claude for code generation...")
    try:
        response = ClaudeHandler.ask(prompt)

        if not response or not response.strip():
            return None

        # Swift ì½”ë“œ ë¸”ë¡ ì œê±°
        code = re.sub(r"^\s*```swift\s*", "", response, flags=re.MULTILINE)
        code = re.sub(r"\s*```\s*$", "", code, flags=re.MULTILINE)

        final_code = code.strip()
        return final_code if final_code else None

    except Exception as e:
        print(f"    âŒ Claude code generation request failed: {e}")
        return None


# --- ë©”ì¸ íŒŒì´í”„ë¼ì¸ ë¡œì§ ---

def load_exclusion_rules(filepath: str) -> dict:
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)["obfuscation_exclusion_rules"]
    except Exception as e:
        print(f"âŒ ê·œì¹™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ '{filepath}': {e}")
        exit(1)


def load_safe_patterns(filepath: str) -> list:
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return [item["description"] for item in json.load(f)["safe_patterns"]]
    except Exception as e:
        print(f"âŒ ì•ˆì „í•œ íŒ¨í„´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ '{filepath}': {e}")
        return []


def create_generation_tasks(rules: dict) -> list:
    print("ğŸ§  Generating comprehensive task list...")
    tasks = []

    all_l2_patterns = []
    for l1, l1_content in rules.items():
        for l2, l2_content in l1_content.get("L2_Patterns", {}).items():
            l2_content.update({"l1_reason": l1, "l2_pattern": l2})
            all_l2_patterns.append(l2_content)

    for pattern in all_l2_patterns:
        rules_content = pattern.get("sufficiency_rules", {})

        # Sufficient combinations
        for i, combo in enumerate(rules_content.get("sufficient_combinations", [])):
            tasks.append({
                "type": "Sufficient_Positive",
                "content": {"pattern": pattern, "evidence": combo},
                "filename": f"{pattern['l1_reason']}_{pattern['l2_pattern']}_sufficient_{i}"
            })

        # Insufficient evidence
        for i, evidence in enumerate(rules_content.get("insufficient_single_evidence", [])):
            tasks.append({
                "type": "Insufficient_Positive",
                "content": {"pattern": pattern, "evidence": [evidence]},
                "filename": f"{pattern['l1_reason']}_{pattern['l2_pattern']}_insufficient_{i}"
            })

        # Negative cases
        tasks.append({
            "type": "Clear_Negative",
            "content": {"pattern": pattern},
            "filename": f"{pattern['l1_reason']}_{pattern['l2_pattern']}_negative"
        })

    # Combined patterns
    for p1, p2 in itertools.combinations(all_l2_patterns, 2):
        filename = f"COMBINED_{p1['l2_pattern']}_{p2['l2_pattern']}"
        tasks.append({
            "type": "Combined_Positive",
            "content": {"pattern1": p1, "pattern2": p2},
            "filename": filename
        })

    print(f"âœ… Task list generated. Total unique tasks: {len(tasks)}")
    return tasks


def process_old_code_files():
    """
    old_gemini_generated, old_claude_generated ë””ë ‰í† ë¦¬ì—ì„œ ê¸°ì¡´ Swift íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    old_tasks = []

    for old_type in ["old_gemini", "old_claude"]:
        paths = get_generator_paths(old_type)
        code_dir = paths["code"]

        if not code_dir.exists():
            print(f"  - {old_type} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {code_dir}")
            continue

        swift_files = list(code_dir.glob("*.swift"))
        print(f"  - {old_type}ì—ì„œ {len(swift_files)}ê°œì˜ Swift íŒŒì¼ ë°œê²¬")

        for swift_file in swift_files:
            # íŒŒì¼ëª…ì—ì„œ .swift í™•ì¥ì ì œê±°í•˜ì—¬ íƒœìŠ¤í¬ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
            task_name = swift_file.stem

            # ë”ë¯¸ íƒœìŠ¤í¬ ìƒì„± (ê¸°ì¡´ íŒŒì¼ ì²˜ë¦¬ìš©)
            dummy_task = {
                "type": "Existing_Code",
                "content": {},
                "filename": task_name
            }

            old_tasks.append((dummy_task, old_type, []))

    return old_tasks


def process_and_save_sample(task_info: tuple):
    """
    í•˜ë‚˜ì˜ íƒœìŠ¤í¬ì™€ ìƒì„±ê¸° íƒ€ì…ì— ëŒ€í•´ ìƒ˜í”Œì„ ìƒì„±í•˜ê³ ,
    ì¤‘ê°„ ê²°ê³¼ë¬¼(ì½”ë“œ, ë ˆì´ë¸”)ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    task, generator_type, safe_patterns = task_info

    task_type = task["type"]
    content = task["content"]
    filename = task["filename"]

    paths = get_generator_paths(generator_type)
    code_path = paths["code"] / f"{filename}.swift"
    input_path = paths["inputs"] / f"{filename}.txt"
    label_path = paths["labels"] / f"{filename}.json"

    # ì´ë¯¸ ìœ íš¨í•œ ë¼ë²¨ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
    if is_valid_json_file(label_path):
        return

    print(f"  - [{generator_type.upper()}] `{filename}` ({task_type}) ìƒ˜í”Œ ìƒì„± ì¤‘...")

    # Swift ì½”ë“œ ë¡œë“œ ë˜ëŠ” ìƒì„±
    swift_code = ""
    if generator_type.startswith("old_"):
        # old íƒ€ì…ì˜ ê²½ìš° ê¸°ì¡´ íŒŒì¼ë§Œ ì½ê¸°
        if code_path.exists() and code_path.stat().st_size > 10:
            try:
                swift_code = code_path.read_text(encoding='utf-8')
            except Exception:
                swift_code = ""

        if not swift_code or not swift_code.strip():
            print(f"    âŒ No existing code found for old generator type")
            return
    else:
        # ìƒˆë¡œìš´ íƒ€ì…ì˜ ê²½ìš° ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        if code_path.exists() and code_path.stat().st_size > 10:
            print(f"    - Reusing existing Swift code.")
            try:
                swift_code = code_path.read_text(encoding='utf-8')
            except Exception:
                swift_code = ""

        if not swift_code or not swift_code.strip():
            if generator_type == "gemini":
                code_gen_func = safe_gemini_code_request
            elif generator_type == "claude":
                code_gen_func = safe_claude_code_request
            else:
                print(f"    âš ï¸ Skipping {generator_type} - not implemented")
                return

            # í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° í¬ë§·íŒ…
            if task_type == "Sufficient_Positive":
                prompt = prompts.GENERATE_SUFFICIENT_POSITIVE_CODE_PROMPT.format(
                    pattern_description=content['pattern']['description'],
                    evidence_list=json.dumps(content['evidence'])
                )
            elif task_type == "Insufficient_Positive":
                prompt = prompts.GENERATE_INSUFFICIENT_POSITIVE_CODE_PROMPT.format(
                    pattern_description=content['pattern']['description'],
                    evidence_list=json.dumps(content['evidence'])
                )
            elif task_type == "Clear_Negative":
                prompt = prompts.GENERATE_NEGATIVE_CODE_PROMPT.format(
                    pattern_description=content['pattern']['description']
                )
            elif task_type == "Combined_Positive":
                p1, p2 = content['pattern1'], content['pattern2']
                p1_evidence = p1.get('sufficiency_rules', {}).get('sufficient_combinations', [[]])[0]
                p2_evidence = p2.get('sufficiency_rules', {}).get('sufficient_combinations', [[]])[0]
                prompt = prompts.GENERATE_COMBINED_CODE_PROMPT.format(
                    pattern1_description=p1['description'],
                    pattern1_evidence=json.dumps(p1_evidence),
                    pattern2_description=p2['description'],
                    pattern2_evidence=json.dumps(p2_evidence)
                )
            else:
                print(f"    âš ï¸ Unknown task type: {task_type}")
                return

            swift_code = code_gen_func(prompt)
            if not swift_code or not swift_code.strip():
                print(f"    âŒ Failed to generate Swift code")
                return

            try:
                code_path.write_text(swift_code, encoding='utf-8')
            except Exception as e:
                print(f"    âŒ Failed to save code: {e}")
                return

    # AST ë¶„ì„
    symbol_info_json = run_swift_analyzer_on_code(swift_code)
    if not symbol_info_json:
        print(f"    âŒ Swift analyzer failed or returned invalid JSON")
        return

    # ë ˆì´ë¸” ìƒì„±
    try:
        label_prompt = prompts.GENERATE_LABEL_PROMPT.format(
            swift_code=swift_code,
            symbol_info_json=symbol_info_json
        )
        input_path.write_text(label_prompt, encoding='utf-8')
    except Exception as e:
        print(f"    âŒ Failed to save input prompt: {e}")
        return

    # ë¼ë²¨ ìƒì„± (í•­ìƒ Gemini 2.5 Pro ì‚¬ìš©)
    final_output_json_str = safe_gemini_label_request(label_prompt)
    if not final_output_json_str:
        print(f"    âŒ Failed to generate valid label")
        try:
            label_path.write_text('{"error": "generation_failed"}', encoding='utf-8')
        except Exception:
            pass
        return

    # ìµœì¢… ì €ì¥
    try:
        label_path.write_text(final_output_json_str, encoding='utf-8')
        print(f"    âœ… Saved artifacts for `{filename}`.")
    except Exception as e:
        print(f"    âŒ Failed to save label: {e}")
        return


def assemble_final_dataset():
    print("\nğŸ“¦ ìµœì¢… ë°ì´í„°ì…‹ ì¡°ë¦½ ì¤‘...")
    datasets = {"gemini": [], "claude": [], "old_gemini": [], "old_claude": [], "combined": []}

    for generator in ["gemini", "claude", "old_gemini", "old_claude"]:
        paths = get_generator_paths(generator)
        label_files = sorted(list(paths["labels"].glob("*.json")))
        if not label_files:
            print(f"  - {generator.capitalize()}: ë¼ë²¨ íŒŒì¼ ì—†ìŒ")
            continue

        success_count = 0
        error_count = 0

        for label_path in tqdm(label_files, desc=f"{generator.capitalize()} ë°ì´í„°ì…‹ ì¡°ë¦½"):
            try:
                # ìœ íš¨í•œ JSON íŒŒì¼ì¸ì§€ í™•ì¸
                if not is_valid_json_file(label_path):
                    error_count += 1
                    continue

                code_path = paths["code"] / (label_path.stem + ".swift")
                input_path = paths["inputs"] / (label_path.stem + ".txt")

                if not code_path.exists() or not input_path.exists():
                    error_count += 1
                    continue

                swift_code = code_path.read_text(encoding='utf-8')
                if not swift_code or not swift_code.strip():
                    error_count += 1
                    continue

                output_json_str = label_path.read_text(encoding='utf-8')
                input_prompt = input_path.read_text(encoding='utf-8')

                # input í”„ë¡¬í”„íŠ¸ì—ì„œ symbol_infoë¥¼ ì¶”ì¶œ (ì´ë¯¸ ìƒì„±ëœ ê²ƒ ì‚¬ìš©)
                symbol_info_json = None
                if "symbol_info_json=" in input_prompt:
                    # í”„ë¡¬í”„íŠ¸ì—ì„œ symbol_info ë¶€ë¶„ ì¶”ì¶œ
                    match = re.search(r'symbol_info_json=(.+?)(?=\n\n|\Z)', input_prompt, re.DOTALL)
                    if match:
                        symbol_info_json = match.group(1).strip()

                # ë§Œì•½ ì¶”ì¶œì— ì‹¤íŒ¨í•˜ë©´ Swift analyzer ë‹¤ì‹œ ì‹¤í–‰
                if not symbol_info_json:
                    symbol_info_json = run_swift_analyzer_on_code(swift_code)
                    if not symbol_info_json:
                        error_count += 1
                        continue

                # JSON íŒŒì‹± ê²€ì¦
                try:
                    symbol_info_dict = json.loads(symbol_info_json)
                    output_dict = json.loads(output_json_str)
                except json.JSONDecodeError:
                    error_count += 1
                    continue

                # ìµœì¢… ë°ì´í„°ì…‹ ì—”íŠ¸ë¦¬ ìƒì„±
                entry = {
                    "instruction": "Identify which identifiers in the Swift code should be excluded from obfuscation based on the provided AST analysis, and provide detailed reasoning.",
                    "input": {
                        "swift_code": swift_code,
                        "symbol_info": symbol_info_dict
                    },
                    "output": output_dict
                }

                datasets[generator].append(entry)
                datasets["combined"].append(entry)
                success_count += 1

            except Exception as e:
                error_count += 1
                print(f"\nâš ï¸ íŒŒì¼ ì¡°ë¦½ ì¤‘ ì—ëŸ¬ ë°œìƒ '{label_path.name}': {e}")

        print(f"  - {generator.capitalize()}: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")

    # ìµœì¢… ë°ì´í„°ì…‹ íŒŒì¼ ì €ì¥
    try:
        with open(FINAL_DATASET_GEMINI_ONLY, "w", encoding="utf-8") as f:
            for entry in datasets["gemini"]:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        with open(FINAL_DATASET_CLAUDE_ONLY, "w", encoding="utf-8") as f:
            for entry in datasets["claude"]:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        # old ë°ì´í„°ë“¤ë„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
        old_gemini_file = OUTPUT_DIR / "old_gemini_dataset.jsonl"
        with open(old_gemini_file, "w", encoding="utf-8") as f:
            for entry in datasets["old_gemini"]:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        old_claude_file = OUTPUT_DIR / "old_claude_dataset.jsonl"
        with open(old_claude_file, "w", encoding="utf-8") as f:
            for entry in datasets["old_claude"]:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")

        with open(FINAL_DATASET_COMBINED, "w", encoding="utf-8") as f:
            for entry in datasets["combined"]:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"âŒ ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")

    return {name: len(ds) for name, ds in datasets.items()}


def main_pipeline():
    # ë””ë ‰í† ë¦¬ ìƒì„± (old ë””ë ‰í† ë¦¬ë“¤ë„ í¬í•¨)
    for gen in ["gemini", "claude", "old_gemini", "old_claude"]:
        paths = get_generator_paths(gen)
        for path in paths.values():
            path.mkdir(parents=True, exist_ok=True)

    print("ğŸš€ ë‚œë…í™” ì œì™¸ ë°ì´í„°ì…‹ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘...")

    # ê·œì¹™ ë° íŒ¨í„´ ë¡œë“œ
    rules = load_exclusion_rules(RULES_FILE)
    safe_patterns = load_safe_patterns(SAFE_PATTERNS_FILE)
    tasks = create_generation_tasks(rules)

    GENERATORS_TO_RUN = ["gemini", "claude"]

    # 1. ìƒˆë¡œìš´ íƒœìŠ¤í¬ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    full_task_list = []
    for gen_type in GENERATORS_TO_RUN:
        for task in tasks:
            full_task_list.append((task, gen_type, safe_patterns))

    # 2. ê¸°ì¡´ old íŒŒì¼ë“¤ ì²˜ë¦¬ íƒœìŠ¤í¬ ì¶”ê°€
    print("ğŸ“ ê¸°ì¡´ old íŒŒì¼ë“¤ ê²€ìƒ‰ ì¤‘...")
    old_tasks = process_old_code_files()
    full_task_list.extend(old_tasks)

    print(f"ì´ {len(full_task_list)}ê°œ íƒœìŠ¤í¬ ì²˜ë¦¬ ì‹œì‘...")
    print(f"  - ìƒˆë¡œìš´ íƒœìŠ¤í¬: {len(full_task_list) - len(old_tasks)}ê°œ")
    print(f"  - ê¸°ì¡´ old íŒŒì¼: {len(old_tasks)}ê°œ")

    # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìƒ˜í”Œ ìƒì„±
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        list(tqdm(
            executor.map(process_and_save_sample, full_task_list),
            total=len(full_task_list),
            desc="ì „ì²´ íƒœìŠ¤í¬ ì²˜ë¦¬ ì¤‘"
        ))

    # ìµœì¢… ë°ì´í„°ì…‹ ì¡°ë¦½
    counts = assemble_final_dataset()

    print(f"\nâœ¨ íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ!")
    print(f"   - Gemini ë°ì´í„°: {counts['gemini']}ê°œ")
    print(f"   - Claude ë°ì´í„°: {counts['claude']}ê°œ")
    print(f"   - Old Gemini ë°ì´í„°: {counts['old_gemini']}ê°œ")
    print(f"   - Old Claude ë°ì´í„°: {counts['old_claude']}ê°œ")
    print(f"   - ì´ Combined ë°ì´í„°: {counts['combined']}ê°œ ìƒì„± ì™„ë£Œ.")


if __name__ == "__main__":
    main_pipeline()